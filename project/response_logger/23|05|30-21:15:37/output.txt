Question 1:
What is the purpose of text normalization?
A. To reduce the effectiveness of NLP models
B. To increase the number of input variables for NLP models
C. To reduce the dimensionality of the input for NLP models
D. To introduce more variations in the words used in the raw text

Answer: C

Question 2:
Which of the following is a component of text normalization?
A. Punctuation addition
B. Contractions reduction
C. Tokenization expansion
D. Stemming removal

Answer: B

Question 3:
What is the advantage of reducing the vocabulary size in NLP?
A. To make the language more difficult to understand
B. To make it easier to identify word variations
C. To minimize the number of features for NLP models
D. To increase the dimensionality of input for NLP models

Answer: C

Question 4:
Which of the following is used to segment running text into words and sequences?
A. Stemming
B. Tokenization
C. Punctuation addition
D. Contractions reduction

Answer: B

Question 5:
What is the purpose of lemmatization?
A. To reduce a word to its stem or root form
B. To segment text into words and sequences
C. To remove all punctuation in the text
D. To expand contractions

Answer: A

Question 6:
What is entropy in intrinsic evaluation measures of language models?
A. A measure of uncertainty
B. A measure of similarity
C. A measure of frequency
D. A measure of perplexity

Answer: A

Question 7:
Which of the following is a way to measure the performance of n-gram language models in predicting the probabilities of sentences?
A. Intrinsic evaluation measures
B. Extrinsic evaluation measures
C. Stemming-based evaluation measures
D. Tokenization-based evaluation measures

Answer: A

Question 8:
What is the purpose of WordNet in lexical semantics?
A. To solve word sense ambiguity
B. To remove offensive words
C. To provide a list of synonyms for each word
D. To classify relationships between words

Answer: D

Question 9:
What is the main advantage of dense word embeddings?
A. They have fewer parameters
B. They are better at capturing synonymy
C. They are easier to include as features in machine learning systems
D. All of the above

Answer: D

Question 10:
What is the objective function in Word2Vec?
A. To maximize the likelihood of the center word given the context words
B. To maximize the entropy of the center word
C. To minimize the sum of squared errors
D. To minimize the log likelihood of the context words given the center word

Answer: D